{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IR2kBS1cQvVw",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Text processing\n",
    "\n",
    "Text preprocessing is a crucial step in any Natural Language Processing (NLP) task. \n",
    "\n",
    "The main goal of text processing is to convert the input text (plain unstructured text) into **linguistically meaninful units**. Much of NLP analyses depends on the correct preprocessing of our data.\n",
    "\n",
    "We have seen that a string is a sequence of characters in python. But text has an underlying linguistic structure.\n",
    "\n",
    "Branch of data science and artificial intelligence that is concerned with how computers can \"understand\" (i.e. process and analyse) language.\n",
    "\n",
    "Text processing involves tasks such as sentence segmentation, tokenization (~ identifying words in a text), lemmatization, part-of-speech tagging, syntactic parsing, semantic role labelling, named entity recognition, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Basic text processing steps\n",
    "\n",
    "We will look at the following common text processing steps:\n",
    "1. Sentence segmentation\n",
    "2. Tokenization (word segmentation)\n",
    "3. Lemmatization\n",
    "4. Part-of-speech tagging\n",
    "5. Dependency parsing (advanced)\n",
    "6. Named entity recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q-vh365FhNwA",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1. Sentence segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kbX-65F_6vBn",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Goal:** identify where sentences begin and end.\n",
    "\n",
    "Example:\n",
    "```\n",
    "A trifling incident thus served to settle a victory.  Now-a days, a soldier is so much of a machine that he seems simply to go through certain evolutions, in which there is no opportunity for the display of personal bravery or cowardice.  He does not know what is going on in other parts of the field, and has no real knowledge, till all be over, whether the day has been lost or won.\n",
    "```\n",
    "\n",
    "Sentences:\n",
    "```\n",
    "A trifling incident thus served to settle a victory.\n",
    "\n",
    "Now-a days, a soldier is so much of a machine that he seems simply to go through certain evolutions, in which there is no opportunity for the display of personal bravery or cowardice.\n",
    "\n",
    "He does not know what is going on in other parts of the field, and has no real knowledge, till all be over, whether the day has been lost or won.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Why do we care?** A sentence is often the smallest unit of language that can convey a message.\n",
    "\n",
    "**What could go wrong?** This:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Input:\n",
    "```\n",
    "Mr. Smith and Mr. Jones went to the shops.\n",
    "```\n",
    "\n",
    "Output:\n",
    "```\n",
    "Mr.\n",
    "Smith and Mr.\n",
    "Jones went to the shops.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ESu39FChIBg",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2. Tokenization (word segmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ue3eBBN8_5B",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Tokenization refers to the process of splitting a string (a sequence of characters) into smaller chunks (linguistically meaningful units), often corresponding to what we would broadly speaking call \"words\".\n",
    "\n",
    "While this may seem a very easy task (\"Just split by space!\"), there are a number of issues that must be taken into consideration. Also, this is language specific (particularly tricky for languages without word delimiters, agglutinating languages, compound words, punctuation, etc.).\n",
    "\n",
    "![picture](images/tokenization.png)\n",
    "\n",
    "Image source: https://spacy.io/usage/linguistic-features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TFP6ii4KhDR4",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3. Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8VgLhExqFq4G",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Lemmatization transforms words to their base forms, i.e. their dictionary forms.\n",
    "\n",
    "| **Token**    | **Lemma**  |\n",
    "|----------|--------|\n",
    "| goose    | goose  |\n",
    "| geese    | goose  |\n",
    "| change   | change |\n",
    "| changes  | change |\n",
    "| changing | change |\n",
    "| changed  | change |\n",
    "\n",
    "**Why do we care?** Python understands \"goose\" and \"geese\" as two completely different and unrelated strings. Or \"change\" and \"changes\", even! Lemmatization is a type of data normalization that reduces a word form to its dictionary form. It is very common in text mining, because the linguistic/semantic cost is relatively small compared to its advantages: it helps reducing the complexity of the document significantly, by reducing forms to their common base."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZwLFL3G5g6VQ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 4. Part-of-speech tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GYFk94vAGFdh",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Part-of-speech (POS) tagging refers to the process of assigning a part-of-speech (i.e. verb, noun, etc) to a word.\n",
    "\n",
    "| Keep | the | pen | under | the | book | . |\n",
    "|------|-----|-----|-------|-----|------|---|\n",
    "| N    | **DET** | **N**   | ADV   | **DET** | **N**    | **PUNCT**  |\n",
    "| **V**    |     | V   | **PREP**  |     | V    |   |\n",
    "|      |     |     | ADJ   |     |      |   |\n",
    "\n",
    "**Why do we need POS tagging?**\n",
    "* Words are ambiguous. Part-of-speech helps disambiguating the most straightforward cases (cases in which POS are different). This is important because the semantics of a word can change significantly (e.g. `book` and `keep`).\n",
    "* We may want to filter out some types of words that we don't need for our future analyses, for example:\n",
    "  * We may want to perform stylometric analyses based on punctuation and function words (i.e. DET, CONJ, PREP...).\n",
    "  * We may want to perform topic modelling based on only words with more semantic content, such as NOUNs and VERBs.\n",
    "  * We may be only interested in actions, and therefore interested in only VERBs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j7pJ5zNDJOKJ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 5. Dependency parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YSkCu-ZdJ11r",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Dependency parsing is the task of identifying syntactic and semantic dependencies in sentences.\n",
    "\n",
    "![picture](images/dependency.png)\n",
    "\n",
    "Suppose, for example, that you're interested in just who performs actions: in this case you'd take only active subjects of sentences (`nsubj`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 6. Named entity recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Named entities are mentions of entities (people, places, organizations, etc) in text. They are key in many projects in Digital Humanities.\n",
    "\n",
    "![picture](images/ner_spacy.png)\n",
    "\n",
    "Image source: https://spacy.io/usage/linguistic-features "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "collapsed_sections": [
    "IR2kBS1cQvVw",
    "BSJPr3vBhbbK",
    "OoHd-2R_vqYy",
    "fOw4Q-ksvYBb",
    "fo8wd_tIwnL3",
    "KVA77p00hTdo",
    "q-vh365FhNwA",
    "tmX8sQ0TCTnM",
    "8ESu39FChIBg",
    "11QjTsM7aDx2",
    "TFP6ii4KhDR4",
    "fCWklZpgZ1no",
    "ZwLFL3G5g6VQ",
    "EfCRpGQBYPzu",
    "Z13dItZkFzdb",
    "jegBvHJ2avOI",
    "e3S9Khn5a2Xv",
    "8ZLruZ1TbFUn",
    "KeSWqf8XgteY",
    "j7pJ5zNDJOKJ"
   ],
   "name": "T2T_text_processing.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
