{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9227e35",
   "metadata": {
    "id": "KVA77p00hTdo",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Basic text processing pipeline with Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd2c884",
   "metadata": {
    "id": "cdq1kREmjrwA",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Spacy is an open-source library for text preprocessing.\n",
    "\n",
    "It features the most common components of the preprocessing pipeline:\n",
    "\n",
    "![](images/nlp_pipeline.png)\n",
    "\n",
    "Image source: https://spacy.io/usage/linguistic-features\n",
    "\n",
    "Spacy takes a string as input, i.e. a sequence of characters, and transforms this string into a sequence of more meaningful units for analyses. Which transformations we want to perform, again, will depend on the nature of our dataset, and the type of analysis we want to perform."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a715df6f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Spacy is a python library, and it has to be installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b50852",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281c2d5c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "... and it has to be imported, to be able to use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54950ed0",
   "metadata": {
    "id": "_gtE6MvSvwWR",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2137faf",
   "metadata": {
    "id": "ng9KTcDj5VKr",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Spacy is based on statistical models that have learned probabilities from datasets richly annotated with linguistic features (more on that later!). A spacy model has learned from observations in the data, so that we can then apply it to new text.\n",
    "\n",
    "Spacy provides easy-to-use pipelines for a variety of languages and for a variety of tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b3c4cf",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](images/spacy_langs.png)\n",
    "\n",
    "Source: https://spacy.io/usage/models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1858b129",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We will use the `en_core_web_sm` pipeline in our examples, which is trained on English data: https://spacy.io/models/en#en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e64542",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In order to start using spacy, we need to download a pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1576a67",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d3b050",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "... And we need to import the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a68d023",
   "metadata": {
    "id": "iCjp6UrojvXJ",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Load English language pipeline and store in variable `nlp`:\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbba3f32",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The `nlp` pipeline takes as input a text and runs it through the pipeline.\n",
    "\n",
    "![](images/nlp_pipeline.png)\n",
    "\n",
    "We store the output in a variable that we call `output`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c59875",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "example = \"This is a great week. Is it not?\"\n",
    "output = nlp(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaaa2dc3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If you print the content of `output`, on the surface it looks like a string. It actually looks like nothing has happened:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75110a4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "example = \"This is a great week. Is it not?\"\n",
    "output = nlp(example)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e4ace8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "But if we print the data type of `output`, we see it's not a string, it's a spacy object called `Doc`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6b0845",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Print the type of `output`:\n",
    "print(type(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b807c43a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A [Doc](https://spacy.io/api/doc) contains the linguistic annotations as a sequences of linguistic units.\n",
    "\n",
    "In other words, variable `output` now contains the linguistic processing of your sentence!\n",
    "\n",
    "![](images/nlp_pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5410c4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Our efforts will now be put into retrieving the linguistic information from the output.\n",
    "\n",
    "We will show you some of the most common ways of using spacy, but there's much more! Check the [documentation](https://spacy.io/usage) if you'd like to know more.\n",
    "\n",
    "First, to recap, that's how to process a text using Spacy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300adc0b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Load English language pipeline and store in variable `nlp`. You may need to download it first,\n",
    "# and you only need to do this step once!\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# The text to process:\n",
    "example = \"This is a great week. Is it not?\"\n",
    "\n",
    "# Process the example text using the pipeline stored in `nlp`, and\n",
    "# store the output in a variable called `output`. This line does most\n",
    "# of the work!!!\n",
    "output = nlp(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcefb8d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now, iterating over the elements in doc allows you to retrieve its linguistic information.\n",
    "\n",
    "In particular, a [`Doc`](https://spacy.io/api/doc) object is a sequence of [`Token`](https://spacy.io/api/token) objects (i.e.~words). Iterating over the elements in a `Doc` object means iterating over its tokens. More interestingly, you will be able to access the token attributes, listed in https://spacy.io/api/token#attributes, using \"dot notation\". For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba3c34e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "example = \"This is a great week. Is it not?\"\n",
    "output = nlp(example)\n",
    "\n",
    "# Iterating over the elements in `output`, using a for-loop:\n",
    "for element in output:\n",
    "    print(element.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045bf221",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "üëÄ As you can see in https://spacy.io/api/token#attributes, `.text` provides the \"verbatim text content\" of a token. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e076b00",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "‚òùÔ∏èIt is common to use a list comprehension instead of a for-loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0651a27a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "example = \"This is a great week. Is it not?\"\n",
    "output = nlp(example)\n",
    "\n",
    "# Iterating over the elements in `output`, using a list comprehension:\n",
    "print([element.text for element in output])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e73224",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "‚úèÔ∏è **Exercise:**\n",
    "\n",
    "First text processing exercise, step-by-step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccafb814",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Download a pipeline in your language of choice. Type your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cbb414",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# 2. Load the trained pipeline into a variable. Type your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f34572",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# 3. Use the pipeline to process a text, iterate over its tokens, and return the verbatim\n",
    "# text content of each token. Type your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d69859",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# 4. Instead of returning the verbatim text content of each token, return its lemma, using\n",
    "# the attribute `.lemma_`. See documentation here: https://spacy.io/api/token#attributes.\n",
    "# Type your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3182c7d7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "‚òùÔ∏è**What if my language does not have any trained pipeline?**\n",
    "\n",
    "Spacy supports learning new languages or fine-tuning models to different domains. It's well-documented [here](https://spacy.io/usage/adding-languages) but it'll be some work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727061a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python (py39)",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
