{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition and Disambiguation\n",
    "\n",
    "**Named-entity recognition (NER**) is a subtask of information extraction that seeks to locate and classify named entities mentioned in text into pre-defined categories such as person names, organizations, locations, medical codes, time expressions, quantities, monetary values, percentages, etc.\n",
    "\n",
    "**Named-entity disambiguation (NED)**, also known as named-entity linking, is the task of assigning a unique identity to entities (such as famous individuals, locations, or companies) mentioned in text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition\n",
    "\n",
    "![](images/ner_pipeline.png)\n",
    "\n",
    "Ok, but how does it work?\n",
    "\n",
    "### Rule-Based Approaches\n",
    "\n",
    "1) E.g., regular expression to extract:\n",
    "\n",
    "- telephone numbers\n",
    "- e-mails\n",
    "- dates\n",
    "- prices\n",
    "- locations (e.g., word + “river” indicates a river)\n",
    "\n",
    "2) Gazetteers: list of proper names of people, locations, organisations, etc.\n",
    "\n",
    "3) Context patterns, such as:\n",
    "- [Person] earns [Money]\n",
    "- [PERSON] joined [ORGANIZATION]\n",
    "- [PERSON] flies to [LOCATION]\n",
    "\n",
    "\n",
    "### Feature Engineering-Based Machine Learning\n",
    "\n",
    "First, you need to have (a lot of) textual data annotated with the NER tags you are interested in discovering. Then you train an algorithm that, provided with the word + additional information regarding it, for instance:\n",
    "- if it starts with a capital letter\n",
    "- if it's at the beginning of a sentence\n",
    "- if it is made by numbers and letters, etc\n",
    "\n",
    "### Neural Network Approaches\n",
    "\n",
    "Instead of providing the algorithm additional information that you think is relevant for the task, you provide a vector representation of each unit under study (for instance each token) and the algorithm will learn how to perform the task. We'll cover this in more details on the last day.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "#spacy.cli.download(\"en_core_web_sm\")\n",
    "\n",
    "# Load the large English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def ner_text(text:str)->list:\n",
    "    \"\"\"\n",
    "    Return the named entities identified in a string\n",
    "\n",
    "    Args:\n",
    "        text (str): a string\n",
    "\n",
    "    Returns:\n",
    "        list: A list containing a series of NER tuples (mention, label)\n",
    "    \"\"\"\n",
    "    assert type(text) is str\n",
    "    processed_text = nlp(text)\n",
    "    ners = [(token.text,token.label_) for token in processed_text.ents]\n",
    "    return ners\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# We read a small sample of 19th Century British Library Books\n",
    "sample_blbooks_df = pd.read_csv('data/bl_books_sample.csv')\n",
    "sample_blbooks_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# We keep only books with a high OCR quality\n",
    "clean_blbooks_df = sample_blbooks_df[sample_blbooks_df['mean_wc_ocr']>0.8]\n",
    "# We convert the column text to a list\n",
    "blbooks_content = clean_blbooks_df['text'].to_list()\n",
    "print (len(blbooks_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_content = blbooks_content[0]\n",
    "print (first_content)\n",
    "ners = ner_text(first_content)\n",
    "print (ners)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✏️ **Exercise:**\n",
    "\n",
    "Write a function that given a string of text it finds the named entities (like `ner_text`) but returns the original text with the identified entities replaced by the ner_tag. For instance:\n",
    "\n",
    "input: \"London is a big city\"\n",
    "\n",
    "output: \"GPE is a big city\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity Linking\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy,spacyfishing\n",
    "\n",
    "text_en = \"Victor Hugo and Honoré de Balzac are French writers who lived in Paris.\"\n",
    "\n",
    "nlp_model_en = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "nlp_model_en.add_pipe(\"entityfishing\")\n",
    "\n",
    "doc_en = nlp_model_en(text_en)\n",
    "\n",
    "for ent in doc_en.ents:\n",
    "        print((ent.text, ent.label_, ent._.kb_qid, ent._.url_wikidata, ent._.nerd_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_en = nlp_model_en(first_content)\n",
    "for ent in doc_en.ents:\n",
    "    print((ent.text, ent.label_, ent._.kb_qid, ent._.url_wikidata, ent._.nerd_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✏️ **Exercise:**\n",
    "\n",
    "Write a function that given a string of text disambiguates the named entities but returns the original text with the identified entities replaced by their wikidata id. For instance:\n",
    "\n",
    "input: \"London is a big city\"\n",
    "\n",
    "output: \"Q84 is a big city\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✏️ **Exercise:**\n",
    "\n",
    "Add a functionality to your function above. A threshold to filter entities with a very low score. This can be hardcoded (for instance over 0.2) or a parameter of your function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('py39dhoxss')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a2e91717858118300f159f516e8add62a50cea7986ea1e6059fd0b766f06d37e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
